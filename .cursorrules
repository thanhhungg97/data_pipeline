# Shopee Data Pipeline - Cursor Rules

You are an expert in data engineering, ETL pipelines, and Python development with Polars.

## Tech Stack
- **Python 3.11+**
- **Polars** - DataFrame library (NOT pandas)
- **FastExcel/OpenPyXL** - Excel reading
- **Plotly** - Interactive charts
- **Tkinter** - GUI (built-in, no extra deps)
- **PyInstaller** - Windows exe builds

## Key Principles
- Write concise, technical responses with accurate Python examples.
- Prioritize readability and reproducibility in data pipelines.
- Use functional programming where appropriate; avoid unnecessary classes.
- Prefer vectorized operations over explicit loops for better performance.
- Use descriptive variable names that reflect the data they contain.
- Follow PEP 8 style guidelines for Python code.

## Polars Best Practices
- Use `pl.len()` instead of deprecated `pl.count()`
- Prefer lazy evaluation with `scan_*` and `.collect()` for large datasets
- Use method chaining for data transformations
- Use `pl.col("name")` for column selection, not `df["name"]`
- Use `.filter()` instead of boolean indexing
- Use `.with_columns()` to add/modify columns
- Use `.group_by().agg()` for aggregations

## Polars Syntax Examples
```python
# Read and transform
df = pl.read_parquet("data.parquet")
df = pl.scan_parquet("data/*.parquet").collect()  # lazy, for large data

# Filter
df.filter(pl.col("status") == "Delivered")
df.filter(pl.col("amount") > 100)

# Add columns
df.with_columns([
    pl.col("date").dt.year().alias("year"),
    (pl.col("price") * pl.col("qty")).alias("total")
])

# Aggregations
df.group_by("region").agg([
    pl.len().alias("count"),
    pl.sum("amount").alias("total_amount"),
    pl.mean("price").alias("avg_price")
])

# Join
df1.join(df2, on="customer_id", how="left")
```

## Data Schema
The Shopee order data has these columns:
- Date (datetime)
- Source (string) - "Shopee"
- Order ID (string)
- Status (string) - "Delivered", "Cancel by cust.", "Returned", "Failed delivery"
- Reason cancelled (string)
- Refund/ Exchange status (string)
- Refund/ Exchange reason (string)
- Region, City, Payment method (mostly null)
- Platform (string) - "MKP"
- Year, Month (int) - added by transform

## File Structure
```
├── main.py                 # CLI entry point
├── app_gui.py              # Windows GUI app (standalone, embedded ETL)
├── src/
│   ├── __init__.py
│   ├── extract.py          # Read Excel files
│   ├── transform.py        # Data transformations
│   └── load.py             # Save to Parquet (partitioned by year/month)
├── visualize.py            # Basic dashboard
├── dashboard_compare.py    # Comparison dashboard with MoM/YoY
├── config.yaml             # Pipeline config
├── requirements.txt        # Python dependencies
├── VERSION                 # Current version number
├── build_exe.py            # PyInstaller build script
├── BUILD_WINDOWS.md        # Windows build instructions
├── .github/workflows/      # CI/CD (build.yml)
└── data/
    ├── raw/                # Input Excel files (gitignored)
    └── processed/          # Output: year/month/orders.parquet (gitignored)
```

## Dashboard Requirements
- Dark theme (bg: #1a1a2e)
- Show percentages prominently, counts secondary
- Month selector dropdown
- Compare: current month vs last month vs same month last year
- Color coding: green = good (delivery), red = bad (cancellation)

## When Modifying
- Keep app_gui.py self-contained (embedded ETL logic) for PyInstaller
- Test locally before pushing (python main.py, python app_gui.py)
- Update VERSION file when releasing
- Tag releases as v1.0.0, v1.1.0, etc.

## Don't
- Don't use pandas - use Polars instead
- Don't use `pl.count()` - use `pl.len()` instead
- Don't add heavy dependencies (keep exe size reasonable)
- Don't commit data files (*.xlsx, *.parquet, data/)

---
globs: "**/*.py"
---

# Shopee Data Pipeline - Cursor Rules

You are an expert in data engineering, ETL pipelines, and Python development with Polars.

## Tech Stack
- **Python 3.11+**
- **Polars** - DataFrame library (NOT pandas)
- **FastExcel/OpenPyXL** - Excel reading
- **Plotly** - Interactive charts
- **Tkinter** - GUI (built-in, no extra deps)
- **PyInstaller** - Windows exe builds

## Key Principles
- Write concise, technical responses with accurate Python examples.
- Prioritize readability and reproducibility in data pipelines.
- Use functional programming where appropriate; avoid unnecessary classes.
- Prefer vectorized operations over explicit loops for better performance.
- Use descriptive variable names that reflect the data they contain.
- Follow PEP 8 style guidelines for Python code.

## Polars Best Practices
- Use `pl.len()` instead of deprecated `pl.count()`
- Prefer lazy evaluation with `scan_*` and `.collect()` for large datasets
- Use method chaining for data transformations
- Use `pl.col("name")` for column selection, not `df["name"]`
- Use `.filter()` instead of boolean indexing
- Use `.with_columns()` to add/modify columns
- Use `.group_by().agg()` for aggregations

## Polars Syntax Examples
```python
# Read and transform
df = pl.read_parquet("data.parquet")
df = pl.scan_parquet("data/*.parquet").collect()  # lazy, for large data

# Filter
df.filter(pl.col("status") == "Delivered")
df.filter(pl.col("amount") > 100)

# Add columns
df.with_columns([
    pl.col("date").dt.year().alias("year"),
    (pl.col("price") * pl.col("qty")).alias("total")
])

# Aggregations
df.group_by("region").agg([
    pl.len().alias("count"),
    pl.sum("amount").alias("total_amount"),
    pl.mean("price").alias("avg_price")
])

# Join
df1.join(df2, on="customer_id", how="left")
```

## Multi-Source Architecture
The pipeline supports multiple data sources (Shopee, Website, Lazada, etc.):
- Configure sources in `config.yaml` with file patterns
- Each source can have different column mappings
- Data is normalized to standard schema during transform
- Output is partitioned by source AND year/month

## Data Schema (Standard)
- Date (datetime)
- Source (string) - "Shopee", "Website", "Lazada", etc.
- Order ID (string)
- Status (string) - "Delivered", "Cancelled", "Returned", "Failed"
- Status_Normalized (string) - standardized status across sources
- Reason cancelled (string)
- Year, Month (int) - added by transform

## Adding a New Source (Simple!)
Just create a folder with the source name:
```
data/raw/
├── shopee/           ← Folder name = Source name
│   ├── Jan 2025.xlsx
│   └── Feb 2025.xlsx
├── website/
│   └── Orders.xlsx
└── lazada/
    └── Sales.xlsx
```

Then run `python main.py` — auto-detects all sources!

## Adding a Source (With Config)
For custom patterns or column mappings, add to `config.yaml`:
```yaml
sources:
  lazada:
    pattern: "Lazada*.xlsx"      # or "lazada/*.xlsx" for subfolder
    source_name: "Lazada"
```

## File Structure
```
├── main.py                 # CLI entry point (multi-source ETL)
├── app_gui.py              # Windows GUI app (standalone, embedded ETL)
├── src/
│   ├── __init__.py
│   ├── extract.py          # Read Excel files (multi-source support)
│   ├── transform.py        # Data transformations + normalization
│   └── load.py             # Save to Parquet (partitioned by source/year/month)
├── visualize.py            # Basic dashboard
├── dashboard_compare.py    # Month comparison dashboard (MoM/YoY)
├── dashboard_sources.py    # Multi-source comparison dashboard
├── config.yaml             # Pipeline + sources config
├── requirements.txt        # Python dependencies
├── VERSION                 # Current version number
├── build_exe.py            # PyInstaller build script
├── BUILD_WINDOWS.md        # Windows build instructions
├── .github/workflows/      # CI/CD (build.yml)
└── data/
    ├── raw/                # Input: Shopee*.xlsx, Website*.xlsx, etc.
    └── processed/          # Output: source/year/month/orders.parquet
```

## Dashboard Requirements
- Dark theme (bg: #1a1a2e)
- Show percentages prominently, counts secondary
- Month selector dropdown
- Compare: current month vs last month vs same month last year
- Color coding: green = good (delivery), red = bad (cancellation)

## When Modifying
- Keep app_gui.py self-contained (embedded ETL logic) for PyInstaller
- Test locally before pushing (python main.py, python app_gui.py)
- Update VERSION file when releasing
- Tag releases as v1.0.0, v1.1.0, etc.

## Don't
- Don't use pandas - use Polars instead
- Don't use `pl.count()` - use `pl.len()` instead
- Don't add heavy dependencies (keep exe size reasonable)
- Don't commit data files (*.xlsx, *.parquet, data/)
